# NotionNext 内存占用过高分析报告

本文档旨在分析和解决 NotionNext 项目在服务器上内存占用过高的问题。

---

## 1. 问题现象

- **服务器监控**: 宝塔面板显示内存占用率持续在 **85%** 以上。
- **进程分析**: `top` 命令显示，PID 为 `20787` 的 `node` 进程占用了超过 **18%** 的物理内存（约 687MB），且虚拟内存（VIRT）高达 **72.4GB**，存在明显的内存管理问题。
- **SWAP 使用**: 系统已使用 **141.2MB** 的 SWAP 交换空间，表明物理内存（RAM）承受较大压力。

---

## 2. 分析过程

### a. 初步诊断

通过分析 `package.json` 文件，我们确认了以下几点：
- **项目类型**: 基于 Next.js 的博客项目，深度集成 Notion。
- **潜在风险**: 项目同时依赖 `ioredis` 和 `memory-cache`，表明存在两种缓存机制。在没有配置 Redis 的情况下，极有可能默认使用了无限制的内存缓存。

### b. 配置审查

我们依次审查了项目的核心配置文件：
1.  **`blog.config.js`**: 发现了分散在 `/conf/` 目录下的多个配置文件，并将注意力集中在与缓存和数据获取相关的配置上。
2.  **`next.config.js`**: 未发现与运行时内存问题直接相关的配置。
3.  **`lib/cache/cache_manager.js`**: **这是问题的关键**。此文件中的 `getApi()` 函数逻辑如下：
    - 如果配置了 `REDIS_URL`，则使用 Redis 缓存。
    - 否则，如果配置了文件缓存，则使用文件缓存。
    - **否则，默认使用 `MemoryCache`（内存缓存）。**
4.  **`lib/cache/memory_cache.js`**: 确认了 `memory-cache` 库虽然设置了10分钟的过期时间，但存在两个主要缺陷：
    - **被动过期**: 缓存不会主动清理，只有在下次被访问时才会检查是否过期。
    - **无大小限制**: 无法防止短时间内大量缓存写入导致的内存激增。

### c. 关联性分析 (`DEPLOY_NOTES.md`)

通过阅读部署笔记，我们进一步确认：
- 服务器曾在**编译阶段**就因内存不足而卡死，并通过启用 **2GB SWAP** 解决了该问题。
- 这表明服务器物理内存本身就比较紧张，启用 SWAP 只是一个临时措施，并未解决应用**运行时**的内存管理缺陷。

---

## 3. 结论

**根本原因**: 项目在未配置 Redis 的情况下，默认使用了 `memory-cache` 作为缓存方案。该方案存在**被动过期**和**无大小限制**的缺陷，导致 Node.js 进程内存持续增长，最终耗尽物理内存并大量使用 SWAP 空间。

---

## 4. 最终解决方案 (已确认)

**方案**: **切换到 Redis 缓存**。

**理由**:
- **专业可靠**: Redis 是专业的内存数据库，提供持久化和高效的内存管理策略（如 LRU）。
- **从根本上解决问题**: 彻底替换掉有缺陷的 `memory-cache` 方案。
- **可扩展性**: 为未来可能的集群部署打下基础。

**实施步骤**:
1.  **获取 Redis 连接信息** (特别是密码)。
2.  **配置项目环境变量** (`REDIS_URL`)。
3.  **重启应用**使配置生效。